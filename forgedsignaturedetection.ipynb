{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2275286,"sourceType":"datasetVersion","datasetId":1370280}],"dockerImageVersionId":30096,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:15:14.333072Z","iopub.execute_input":"2024-08-21T02:15:14.333559Z","iopub.status.idle":"2024-08-21T02:15:14.345768Z","shell.execute_reply.started":"2024-08-21T02:15:14.333452Z","shell.execute_reply":"2024-08-21T02:15:14.344491Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport os\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport matplotlib.cm as cm\nfrom scipy import ndimage\nfrom skimage.measure import regionprops\nfrom skimage import io\nfrom skimage.filters import threshold_otsu   # For finding the threshold for grayscale to binary conversion\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior() \nfrom tensorflow.python.framework import ops\nimport pandas as pd\nimport numpy as np\nfrom time import time\nimport keras","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-21T02:15:14.347872Z","iopub.execute_input":"2024-08-21T02:15:14.348437Z","iopub.status.idle":"2024-08-21T02:15:23.444113Z","shell.execute_reply.started":"2024-08-21T02:15:14.348386Z","shell.execute_reply":"2024-08-21T02:15:23.442975Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"genuine_image_paths = \"../input/forgedsignature/real\"\nforged_image_paths = \"../input/forgedsignature/forged\"","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:15:23.446988Z","iopub.execute_input":"2024-08-21T02:15:23.447485Z","iopub.status.idle":"2024-08-21T02:15:23.452754Z","shell.execute_reply.started":"2024-08-21T02:15:23.447430Z","shell.execute_reply":"2024-08-21T02:15:23.451385Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing the image","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def rgbgrey(img):\n    # Converts rgb to grayscale\n    greyimg = np.zeros((img.shape[0], img.shape[1]))\n    for row in range(len(img)):\n        for col in range(len(img[row])):\n            greyimg[row][col] = np.average(img[row][col])\n    return greyimg","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:15:23.455244Z","iopub.execute_input":"2024-08-21T02:15:23.455719Z","iopub.status.idle":"2024-08-21T02:15:23.489668Z","shell.execute_reply.started":"2024-08-21T02:15:23.455671Z","shell.execute_reply":"2024-08-21T02:15:23.488263Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def greybin(img):\n    # Converts grayscale to binary\n    blur_radius = 0.8\n    img = ndimage.gaussian_filter(img, blur_radius)  # to remove small components or noise\n#     img = ndimage.binary_erosion(img).astype(img.dtype)\n    thres = threshold_otsu(img)\n    binimg = img > thres\n    binimg = np.logical_not(binimg)\n    return binimg","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:15:23.491470Z","iopub.execute_input":"2024-08-21T02:15:23.491898Z","iopub.status.idle":"2024-08-21T02:15:23.504136Z","shell.execute_reply.started":"2024-08-21T02:15:23.491857Z","shell.execute_reply":"2024-08-21T02:15:23.502586Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def preproc(path, img=None, display=True):\n    if img is None:\n        img = mpimg.imread(path)\n    if display:\n        plt.imshow(img)\n        plt.show()\n    grey = rgbgrey(img) #rgb to grey\n    if display:\n        plt.imshow(grey, cmap = matplotlib.cm.Greys_r)\n        plt.show()\n    binimg = greybin(grey) #grey to binary\n    if display:\n        plt.imshow(binimg, cmap = matplotlib.cm.Greys_r)\n        plt.show()\n    r, c = np.where(binimg==1)\n    # Now we will make a bounding box with the boundary as the position of pixels on extreme.\n    # Thus we will get a cropped image with only the signature part.\n    signimg = binimg[r.min(): r.max(), c.min(): c.max()]\n    if display:\n        plt.imshow(signimg, cmap = matplotlib.cm.Greys_r)\n        plt.show()\n    return signimg","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:15:23.505881Z","iopub.execute_input":"2024-08-21T02:15:23.506254Z","iopub.status.idle":"2024-08-21T02:15:23.518574Z","shell.execute_reply.started":"2024-08-21T02:15:23.506216Z","shell.execute_reply":"2024-08-21T02:15:23.517141Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extraction","metadata":{}},{"cell_type":"code","source":"def Ratio(img):\n    a = 0\n    for row in range(len(img)):\n        for col in range(len(img[0])):\n            if img[row][col]==True:\n                a = a+1\n    total = img.shape[0] * img.shape[1]\n    return a/total","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:15:23.520047Z","iopub.execute_input":"2024-08-21T02:15:23.520471Z","iopub.status.idle":"2024-08-21T02:15:23.540257Z","shell.execute_reply.started":"2024-08-21T02:15:23.520408Z","shell.execute_reply":"2024-08-21T02:15:23.538837Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def Centroid(img):\n    numOfWhites = 0\n    a = np.array([0,0])\n    for row in range(len(img)):\n        for col in range(len(img[0])):\n            if img[row][col]==True:\n                b = np.array([row,col])\n                a = np.add(a,b)\n                numOfWhites += 1\n    rowcols = np.array([img.shape[0], img.shape[1]])\n    centroid = a/numOfWhites\n    centroid = centroid/rowcols\n    return centroid[0], centroid[1]","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:15:23.541837Z","iopub.execute_input":"2024-08-21T02:15:23.542231Z","iopub.status.idle":"2024-08-21T02:15:23.556828Z","shell.execute_reply.started":"2024-08-21T02:15:23.542179Z","shell.execute_reply":"2024-08-21T02:15:23.555558Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def EccentricitySolidity(img):\n    r = regionprops(img.astype(\"int8\"))\n    return r[0].eccentricity, r[0].solidity","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:15:23.559957Z","iopub.execute_input":"2024-08-21T02:15:23.560730Z","iopub.status.idle":"2024-08-21T02:15:23.572171Z","shell.execute_reply.started":"2024-08-21T02:15:23.560681Z","shell.execute_reply":"2024-08-21T02:15:23.570679Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def SkewKurtosis(img):\n    h,w = img.shape\n    x = range(w)  # cols value\n    y = range(h)  # rows value\n    #calculate projections along the x and y axes\n    xp = np.sum(img,axis=0)\n    yp = np.sum(img,axis=1)\n    #centroid\n    cx = np.sum(x*xp)/np.sum(xp)\n    cy = np.sum(y*yp)/np.sum(yp)\n    #standard deviation\n    x2 = (x-cx)**2\n    y2 = (y-cy)**2\n    sx = np.sqrt(np.sum(x2*xp)/np.sum(img))\n    sy = np.sqrt(np.sum(y2*yp)/np.sum(img))\n    \n    #skewness\n    x3 = (x-cx)**3\n    y3 = (y-cy)**3\n    skewx = np.sum(xp*x3)/(np.sum(img) * sx**3)\n    skewy = np.sum(yp*y3)/(np.sum(img) * sy**3)\n\n    #Kurtosis\n    x4 = (x-cx)**4\n    y4 = (y-cy)**4\n    # 3 is subtracted to calculate relative to the normal distribution\n    kurtx = np.sum(xp*x4)/(np.sum(img) * sx**4) - 3\n    kurty = np.sum(yp*y4)/(np.sum(img) * sy**4) - 3\n\n    return (skewx , skewy), (kurtx, kurty)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:15:23.574245Z","iopub.execute_input":"2024-08-21T02:15:23.574639Z","iopub.status.idle":"2024-08-21T02:15:23.589798Z","shell.execute_reply.started":"2024-08-21T02:15:23.574602Z","shell.execute_reply":"2024-08-21T02:15:23.588651Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def getFeatures(path, img=None, display=False):\n    if img is None:\n        img = mpimg.imread(path)\n    img = preproc(path, display=display)\n    ratio = Ratio(img)\n    centroid = Centroid(img)\n    eccentricity, solidity = EccentricitySolidity(img)\n    skewness, kurtosis = SkewKurtosis(img)\n    retVal = (ratio, centroid, eccentricity, solidity, skewness, kurtosis)\n    return retVal","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:15:23.591824Z","iopub.execute_input":"2024-08-21T02:15:23.592329Z","iopub.status.idle":"2024-08-21T02:15:23.611525Z","shell.execute_reply.started":"2024-08-21T02:15:23.592275Z","shell.execute_reply":"2024-08-21T02:15:23.609880Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def getCSVFeatures(path, img=None, display=False):\n    if img is None:\n        img = mpimg.imread(path)\n    temp = getFeatures(path, display=display)\n    features = (temp[0], temp[1][0], temp[1][1], temp[2], temp[3], temp[4][0], temp[4][1], temp[5][0], temp[5][1])\n    return features","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:15:23.613225Z","iopub.execute_input":"2024-08-21T02:15:23.613601Z","iopub.status.idle":"2024-08-21T02:15:23.625139Z","shell.execute_reply.started":"2024-08-21T02:15:23.613555Z","shell.execute_reply":"2024-08-21T02:15:23.623741Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Saving the features","metadata":{}},{"cell_type":"code","source":"def makeCSV():\n    if not(os.path.exists('./')):\n        os.mkdir('./')\n        print('New folder \"Features\" created')\n    if not(os.path.exists('./Training')):\n        os.mkdir('./Training')\n        print('New folder \"Features/Training\" created')\n    if not(os.path.exists('./Testing')):\n        os.mkdir('./Testing')\n        print('New folder \"Features/Testing\" created')\n    # genuine signatures path\n    gpath = genuine_image_paths\n    # forged signatures path\n    fpath = forged_image_paths\n    for person in range(1,13):\n        per = ('00'+str(person))[-3:]\n        print('Saving features for person id-',per)\n        \n        with open('./Training/training_'+per+'.csv', 'w') as handle:\n            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n            # Training set\n            for i in range(0,3):\n                source = os.path.join(gpath, per+per+'_00'+str(i)+'.png')\n                features = getCSVFeatures(path=source)\n                handle.write(','.join(map(str, features))+',1\\n')\n            for i in range(0,3):\n                source = os.path.join(fpath, '021'+per+'_00'+str(i)+'.png')\n                features = getCSVFeatures(path=source)\n                handle.write(','.join(map(str, features))+',0\\n')\n        \n        with open('./Testing/testing_'+per+'.csv', 'w') as handle:\n            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n            # Testing set\n            for i in range(3, 5):\n                source = os.path.join(gpath, per+per+'_00'+str(i)+'.png')\n                features = getCSVFeatures(path=source)\n                handle.write(','.join(map(str, features))+',1\\n')\n            for i in range(3,5):\n                source = os.path.join(fpath, '021'+per+'_00'+str(i)+'.png')\n                features = getCSVFeatures(path=source)\n                handle.write(','.join(map(str, features))+',0\\n')","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:15:23.626933Z","iopub.execute_input":"2024-08-21T02:15:23.627299Z","iopub.status.idle":"2024-08-21T02:15:23.645197Z","shell.execute_reply.started":"2024-08-21T02:15:23.627263Z","shell.execute_reply":"2024-08-21T02:15:23.643958Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"makeCSV()","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:15:23.647226Z","iopub.execute_input":"2024-08-21T02:15:23.647757Z","iopub.status.idle":"2024-08-21T02:16:13.432583Z","shell.execute_reply.started":"2024-08-21T02:15:23.647705Z","shell.execute_reply":"2024-08-21T02:16:13.431320Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"New folder \"Features/Training\" created\nNew folder \"Features/Testing\" created\nSaving features for person id- 001\nSaving features for person id- 002\nSaving features for person id- 003\nSaving features for person id- 004\nSaving features for person id- 005\nSaving features for person id- 006\nSaving features for person id- 007\nSaving features for person id- 008\nSaving features for person id- 009\nSaving features for person id- 010\nSaving features for person id- 011\nSaving features for person id- 012\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# TF Model","metadata":{}},{"cell_type":"code","source":"def testing(path):\n    feature = getCSVFeatures(path)\n    if not(os.path.exists('./TestFeatures')):\n        os.mkdir('./TestFeatures')\n    with open('./TestFeatures/testcsv.csv', 'w') as handle:\n        handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y\\n')\n        handle.write(','.join(map(str, feature))+'\\n')","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:16:13.434321Z","iopub.execute_input":"2024-08-21T02:16:13.434808Z","iopub.status.idle":"2024-08-21T02:16:13.441867Z","shell.execute_reply.started":"2024-08-21T02:16:13.434736Z","shell.execute_reply":"2024-08-21T02:16:13.440524Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"n_input = 9\ntrain_person_id = input(\"Enter person's id : \")\ntest_image_path = input(\"Enter path of signature image : \")\ntrain_path = './Training/training_'+train_person_id+'.csv'\ntesting(test_image_path)\ntest_path = './TestFeatures/testcsv.csv'\n\n\ndef readCSV(train_path, test_path, type2=False):\n    # Reading train data\n    df = pd.read_csv(train_path, usecols=range(n_input))\n    train_input = np.array(df.values)\n    train_input = train_input.astype(np.float32, copy=False)  # Converting input to float_32\n    df = pd.read_csv(train_path, usecols=(n_input,))\n    temp = [elem[0] for elem in df.values]\n    correct = np.array(temp)\n    corr_train = keras.utils.to_categorical(correct,2)      # Converting to one hot\n    # Reading test data\n    df = pd.read_csv(test_path, usecols=range(n_input))\n    test_input = np.array(df.values)\n    test_input = test_input.astype(np.float32, copy=False)\n    if not(type2):\n        df = pd.read_csv(test_path, usecols=(n_input,))\n        temp = [elem[0] for elem in df.values]\n        correct = np.array(temp)\n        corr_test = kearas.utils.to_categorical(correct,2)      # Converting to one hot\n    if not(type2):\n        return train_input, corr_train, test_input, corr_test\n    else:\n        return train_input, corr_train, test_input\n\nops.reset_default_graph()\n# Parameters\nlearning_rate = 0.001\ntraining_epochs = 1000\ndisplay_step = 1\n\n# Network Parameters\nn_hidden_1 = 7 # 1st layer number of neurons\nn_hidden_2 = 10 # 2nd layer number of neurons\nn_hidden_3 = 30 # 3rd layer\nn_classes = 2 # no. of classes (genuine or forged)\n\n# tf Graph input\nX = tf.placeholder(\"float\", [None, n_input])\nY = tf.placeholder(\"float\", [None, n_classes])\n\n# Store layers weight & bias\nweights = {\n    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], seed=1)),\n    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n    'h3': tf.Variable(tf.random_normal([n_hidden_2, n_hidden_3])),\n    'out': tf.Variable(tf.random_normal([n_hidden_1, n_classes], seed=2))\n}\nbiases = {\n    'b1': tf.Variable(tf.random_normal([n_hidden_1], seed=3)),\n    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n    'b3': tf.Variable(tf.random_normal([n_hidden_3])),\n    'out': tf.Variable(tf.random_normal([n_classes], seed=4))\n}\n\n\n# Create model\ndef multilayer_perceptron(x):\n    layer_1 = tf.tanh((tf.matmul(x, weights['h1']) + biases['b1']))\n    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n    out_layer = tf.tanh(tf.matmul(layer_1, weights['out']) + biases['out'])\n    return out_layer\n\n# Construct model\nlogits = multilayer_perceptron(X)\n\n# Define loss and optimizer\n\nloss_op = tf.reduce_mean(tf.squared_difference(logits, Y))\noptimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\ntrain_op = optimizer.minimize(loss_op)\n# For accuracies\npred = tf.nn.softmax(logits)  # Apply softmax to logits\ncorrect_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(Y,1))\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n# Initializing the variables\ninit = tf.global_variables_initializer()\n\ndef evaluate(train_path, test_path, type2=False):   \n    if not(type2):\n        train_input, corr_train, test_input, corr_test = readCSV(train_path, test_path)\n    else:\n        train_input, corr_train, test_input = readCSV(train_path, test_path, type2)\n    ans = 'Random'\n    with tf.Session() as sess:\n        sess.run(init)\n        # Training cycle\n        for epoch in range(training_epochs):\n            # Run optimization op (backprop) and cost op (to get loss value)\n            _, cost = sess.run([train_op, loss_op], feed_dict={X: train_input, Y: corr_train})\n            if cost<0.0001:\n                break\n#             # Display logs per epoch step\n#             if epoch % 999 == 0:\n#                 print(\"Epoch:\", '%04d' % (epoch+1), \"cost={:.9f}\".format(cost))\n#         print(\"Optimization Finished!\")\n        \n        # Finding accuracies\n        accuracy1 =  accuracy.eval({X: train_input, Y: corr_train})\n        #print(\"Accuracy for train:\", accuracy1)\n        #print(\"Accuracy for test:\", accuracy2)\n        if type2 is False:\n            accuracy2 =  accuracy.eval({X: test_input, Y: corr_test})\n            return accuracy1, accuracy2\n        else:\n            prediction = pred.eval({X: test_input})\n            if prediction[0][1]>prediction[0][0]:\n                print('Genuine Image')\n                return True\n            else:\n                print('Forged Image')\n                return False\n\n\ndef trainAndTest(rate=0.001, epochs=1700, neurons=7, display=False):    \n    start = time()\n\n    # Parameters\n    global training_rate, training_epochs, n_hidden_1\n    learning_rate = rate\n    training_epochs = epochs\n\n    # Network Parameters\n    n_hidden_1 = neurons # 1st layer number of neurons\n    n_hidden_2 = 7 # 2nd layer number of neurons\n    n_hidden_3 = 30 # 3rd layer\n\n    train_avg, test_avg = 0, 0\n    n = 10\n    for i in range(1,n+1):\n        if display:\n            print(\"Running for Person id\",i)\n        temp = ('0'+str(i))[-2:]\n        train_score, test_score = evaluate(train_path.replace('01',temp), test_path.replace('01',temp))\n        train_avg += train_score\n        test_avg += test_score\n    if display:\n#         print(\"Number of neurons in Hidden layer-\", n_hidden_1)\n        print(\"Training average-\", train_avg/n)\n        print(\"Testing average-\", test_avg/n)\n        print(\"Time taken-\", time()-start)\n    return train_avg/n, test_avg/n, (time()-start)/n\n\n\nevaluate(train_path, test_path, type2=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T02:33:36.231719Z","iopub.execute_input":"2024-08-21T02:33:36.232143Z","iopub.status.idle":"2024-08-21T02:33:45.807260Z","shell.execute_reply.started":"2024-08-21T02:33:36.232107Z","shell.execute_reply":"2024-08-21T02:33:45.806059Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter person's id :  001\nEnter path of signature image :  /kaggle/input/forgedsignature/forged/021001_001.png\n"},{"name":"stdout","text":"Forged Image\n","output_type":"stream"},{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"False"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}